- step:
    name: load_data
    image: docker.io/python:3.10
    environment: pro-trial-prod-oci-vm-gpu-a10-1
    command:
      - pip install -r requirements.txt
      - python load_data.py {parameters}
    inputs:
      - name: images
        default: https://s3.eu-central-1.amazonaws.com/avg-kitti/data_object_image_2.zip
        description: Input dataset as a tar/zip package
      - name: labels
        default: https://s3.eu-central-1.amazonaws.com/avg-kitti/data_object_label_2.zip
        description: Input dataset labels as a tar/zip package
      - name: specs
        default: datum://0197a7ea-49a6-5ce6-81a8-907f8325268a
        description: Sample configuration file shown below converts the 100% KITTI dataset to the training set.
    parameters:
      - name: num_plot_images
        type: integer
        default: 10
        description: Number of images to plot
      - name: subset
        type: integer
        default: 2000
- step:
    name: train
    image: nvcr.io/nvidia/tao/tao-toolkit:5.0.0-tf1.15.5
    environment: pro-trial-prod-oci-vm-gpu-a10-1
    inputs:
      - name: dataset
        default: dataset://KITTI/version3
        description: Path to the dataset created in the previous step
        keep-directories: full
      - name: specs
        default: datum://0197fe54-cead-ec87-47b3-033c295fafac
        description: Sample configuration file shown below converts the 100% KITTI dataset to the training set.
      - name: train_specs
        default: datum://0197cd67-a25d-9804-536a-2d420f98ee3a
      - name: pretrained_model
        default: datum://0197f671-cb76-c9d9-8033-46ca3d8a1335
    parameters:
      - name: epochs
        type: integer
        default: 10
      - name: batch_size_per_gpu
        type: integer
        default: 4
      - name: use_batch_norm
        type: flag
        default: true
    command:
      - pip install -r requirements.txt
      - python train.py {parameters}
    environment-variables:
      - name: NGC_API_KEY
        default: ${NGC_API_KEY}
        description: NGC API key
      - name: USER_EXPERIMENT_DIR
        default: "/valohai/outputs/tao-experiments/detectnet_v2"
        description: Directory where the experiment outputs will be stored
      - name: NUM_GPUS
        default: "1"
        description: Number of GPUs to use for training
      - name: SPECS_DIR
        default: "/valohai/outputs/tao-experiments/specs"
        description: Directory where the specs will be stored
      - name: LOCAL_PROJECT_DIR
        default: "/project"
      - name: TAO_DOCKER_DISABLE
        default: "1"
        description: Disable the Docker config override for the TAO Toolkit (Leave this as it is)
      - name: TF_ALLOW_IOLIBS
        default: "1"
        description: Allow TensorFlow to use I/O libraries (Leave this as it is)
      - name: TAO_DOCKER_CONFIG_OVERRIDE
        default: "1"
        description: Override the Docker configuration for the TAO Toolkit (Leave this as it is)
      - name: TF_RECORDS_DIR
        default: "/workspace/tao-experiments/data/tfrecords/"
        description: Directory where the TFRecords will be stored
      - name: TRAINING_DIR
        default: "/workspace/tao-experiments/data/training"
        description: Directory where the training data will be stored

- step:
    name: evaluate
    image: nvcr.io/nvidia/tao/tao-toolkit:5.0.0-tf1.15.5
    environment: pro-trial-prod-oci-vm-gpu-a10-1
    inputs:
      - name: dataset
        default: dataset://KITTI/version3
        description: Path to the dataset created in the previous step
        keep-directories: full
      - name: train_specs
        default: datum://0198088c-d64c-946c-ba4e-4ef8d9cc043e
      - name: tfrecords
        default: datum://0198088c-d6fc-a57b-c1c7-9e0e9c1b8b94
      - name: model
        default: datum://0198088c-d3dd-e323-ed85-494663385156
    command:
      - pip install -r requirements.txt
      - python evaluate.py
    environment-variables:
      - name: NGC_API_KEY
        default: ${NGC_API_KEY}
        description: NGC API key
      - name: USER_EXPERIMENT_DIR
        default: "/valohai/outputs/tao-experiments/detectnet_v2"
        description: Directory where the experiment outputs will be stored
      - name: NUM_GPUS
        default: "1"
        description: Number of GPUs to use for training
      - name: SPECS_DIR
        default: "/valohai/outputs/tao-experiments/specs"
        description: Directory where the specs will be stored
      - name: LOCAL_PROJECT_DIR
        default: "/project"
      - name: TAO_DOCKER_DISABLE
        default: "1"
        description: Disable the Docker config override for the TAO Toolkit (Leave this as it is)
      - name: TF_ALLOW_IOLIBS
        default: "1"
        description: Allow TensorFlow to use I/O libraries (Leave this as it is)
      - name: TAO_DOCKER_CONFIG_OVERRIDE
        default: "1"
        description: Override the Docker configuration for the TAO Toolkit (Leave this as it is)
      - name: TF_RECORDS_DIR
        default: "/workspace/tao-experiments/data/tfrecords"
        description: Directory where the TFRecords will be stored
      - name: TRAINING_DIR
        default: "/workspace/tao-experiments/data/training"
        description: Directory where the training data will be stored
- pipeline:
    name: train_and_evaluate
    parameters:
      - name: epochs
        default: 10
        targets:
          - train.parameters.epochs
      - name: batch_size_per_gpu
        default: 8
        targets:
          - train.parameters.batch_size_per_gpu
      - name: use_batch_norm
        default: true
        targets:
          - train.parameters.use_batch_norm
    nodes:
      - name: load_data
        type: execution
        step: load_data
      - name: train
        type: execution
        step: train
        override:
          inputs:
            - name: dataset
      - name: evaluate
        type: execution
        step: evaluate
        override:
          inputs:
            - name: dataset
        actions:
          - when: node-starting
            then: require-approval
    edges:
      - [load_data.outputs.*.zip, train.input.dataset]
      - [load_data.outputs.*.zip, evaluate.input.dataset]
      - [train.outputs.*.hdf5, evaluate.input.model]
      - [train.outputs.*.zip, evaluate.input.tfrecords]
      - [train.outputs.*.txt, evaluate.input.train_specs]
